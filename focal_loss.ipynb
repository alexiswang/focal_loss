{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I'm trying to work out how to create a classifier that inherits from LGBMModel with focal loss as objective function. The implementatiom of focal loss is borrowed from [Max's blog](https://maxhalford.github.io/blog/lightgbm-focal-loss/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62   b'0'  \n",
       "1  0.125895 -0.008983  0.014724    2.69   b'0'  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66   b'0'  \n",
       "3 -0.221929  0.062723  0.061458  123.50   b'0'  \n",
       "4  0.502292  0.219422  0.215153   69.99   b'0'  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "data = arff.loadarff('phpKo8OWT.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "y = y.map({b'0': 0, b'1':1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logloss implementation\n",
    "\n",
    "First let's try to make this work for binary logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "from sklearn import metrics\n",
    "\n",
    "def logloss_init_score(y):\n",
    "    p = y.mean()\n",
    "    p = np.clip(p, 1e-15, 1 - 1e-15)\n",
    "    log_odds = np.log(p / (1 - p))\n",
    "    return log_odds\n",
    "\n",
    "def logloss_objective(preds, train_data):\n",
    "    y = train_data.get_label()\n",
    "    p = special.expit(preds)\n",
    "    grad = p - y\n",
    "    hess = p * (1 - p)\n",
    "    return grad, hess\n",
    "\n",
    "def logloss_metric(preds, train_data):\n",
    "    y = train_data.get_label()\n",
    "    p = special.expit(preds)\n",
    "    is_higher_better = False\n",
    "    return 'logloss', metrics.log_loss(y, p), is_higher_better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 379, number of negative: 213226\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 213605, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001774 -> initscore=-6.332572\n",
      "[LightGBM] [Info] Start training from score -6.332572\n",
      "Test ROC AUC: 0.97091\n",
      "Test logloss 0.00327\n"
     ]
    }
   ],
   "source": [
    "# this is the default way of training a lightgbm model\n",
    "# IMPORTANT NOTE: we need to set objective and learning rate explicitly so we can get the same result\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.01,\n",
    "    'random_seed': 0 }\n",
    "\n",
    "train_set = lgb.Dataset(data=X_train, label=y_train)\n",
    "model = lgb.train(params=params, train_set=train_set, valid_sets=train_set)\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Test ROC AUC: {metrics.roc_auc_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Test logloss {metrics.log_loss(y_test, y_pred):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 379, number of negative: 213226\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 213605, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001774 -> initscore=-6.332572\n",
      "[LightGBM] [Info] Start training from score -6.332572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Metric during training'}, xlabel='Iterations', ylabel='binary_logloss'>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightgbm import plot_metric\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "model.set_params(**{\"learning_rate\": 0.01})\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "plot_metric(booster=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 213605, number of used features: 30\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "Test ROC AUC: 0.97091\n",
      "Test logloss 0.00327\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "params = {\n",
    "        'learning_rate': 0.01,\n",
    "          'random_seed': 0,\n",
    "          'objective': logloss_objective\n",
    "}\n",
    "init_scores = np.full_like(y_train, logloss_init_score(y_train), dtype=float)\n",
    "train_set = lgb.Dataset(data=X_train, label=y_train, init_score=init_scores)\n",
    "model = lgb.train(params=params, train_set=train_set, feval=logloss_metric)\n",
    "y_pred = special.expit(logloss_init_score(y_train)+model.predict(X_test))\n",
    "print(f\"Test ROC AUC: {metrics.roc_auc_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Test logloss {metrics.log_loss(y_test, y_pred):.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMModel\n",
    "from lightgbm.compat import SKLEARN_INSTALLED, LGBMNotFittedError, _LGBMClassifierBase\n",
    "from lightgbm.callback import _EvalResultDict, record_evaluation\n",
    "class CustomLGBMClassifier(_LGBMClassifierBase, LGBMModel):\n",
    "\n",
    "    # def __init__(self, objective=None, init_score=0, **kwargs):\n",
    "    #     super().__init__(**kwargs)\n",
    "        # self.objective = logloss_objective\n",
    "        # self.eval_metric = logloss_metric\n",
    "        # self.init_score = None\n",
    "        # self.init_score = init_score\n",
    "\n",
    "\n",
    "    def __is_fitted__(self):\n",
    "        return getattr(self, \"fitted_\", False)\n",
    "\n",
    "    def get_params(self, deep: bool = True):\n",
    "        \n",
    "        params = super().get_params(deep=deep)\n",
    "\n",
    "        if hasattr(self, \"obj_alpha\"):\n",
    "            params.update({\"obj_alpha\": self.obj_alpha})\n",
    "        if hasattr(self, \"obj_gamma\"):\n",
    "            params.update({\"obj_gamma\": self.obj_gamma})        \n",
    "        # self.objective = params[\"objective\"] = FocalLoss().lgb_obj  \n",
    "        #      \n",
    "        return params\n",
    "\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "            if hasattr(self, f\"_{key}\"):\n",
    "                setattr(self, f\"_{key}\", value)\n",
    "            self._other_params[key] = value\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def _process_params(self, stage):\n",
    "\n",
    "        assert stage in {\"fit\", \"predict\"}\n",
    "        params = self.get_params()\n",
    "\n",
    "        if \"obj_alpha\" not in params.keys():\n",
    "            self.obj_alpha = params[\"obj_alpha\"] = 0.3\n",
    "        if  \"obj_gamma\" not in params.keys():\n",
    "            self.obj_gamma = params[\"obj_gamma\"] = 1\n",
    "\n",
    "        if stage == \"fit\":\n",
    "            params[\"objective\"] = FocalLoss(alpha=params[\"obj_alpha\"], gamma=params[\"obj_gamma\"]).lgb_obj\n",
    "            params[\"random_seed\"] = 0\n",
    "        \n",
    "        \n",
    "        self.eval_metric = FocalLoss(alpha=params[\"obj_alpha\"], gamma=params[\"obj_gamma\"]).lgb_eval\n",
    "\n",
    "        return params\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.init_score = FocalLoss().init_score(y)\n",
    "        init_scores = np.full_like(y, self.init_score, dtype=float)\n",
    "        train_set = lgb.Dataset(data=X, label=y, init_score=init_scores)\n",
    "\n",
    "        params = self._process_params(stage=\"fit\")\n",
    "\n",
    "        valid_sets = []\n",
    "        if eval_set is not None:\n",
    "            if isinstance(eval_set, tuple):\n",
    "                eval_set = [eval_set]\n",
    "            for i, valid_data in enumerate(eval_set):\n",
    "                if valid_data[0] is X and valid_data[1] is y:\n",
    "                    valid_set = train_set\n",
    "                else:\n",
    "                    valid_init_scores = np.full_like(valid_data[1], self.init_score, dtype=float)\n",
    "                    valid_set = lgb.Dataset(data=valid_data[0], label=valid_data[1], init_score=valid_init_scores)\n",
    "                valid_sets.append(valid_set)\n",
    "\n",
    "        if callbacks is None:\n",
    "            callbacks = []\n",
    "\n",
    "        evals_result: _EvalResultDict={}\n",
    "        callbacks.append(record_evaluation(evals_result))\n",
    "\n",
    "        \n",
    "        self._Booster = lgb.train(\n",
    "            params=params, \n",
    "            train_set=train_set, \n",
    "            valid_sets=valid_sets, \n",
    "            feval=self.eval_metric, \n",
    "            callbacks=callbacks)\n",
    "        \n",
    "        self._evals_result = evals_result\n",
    "        self.fitted_ = True\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        result = self._Booster.predict(X)\n",
    "        preds = special.expit(self.init_score + result)\n",
    "        # return preds\n",
    "        return np.vstack((1.-preds, preds)).transpose()\n",
    "    \n",
    "    @property\n",
    "    def classes_(self) -> np.ndarray:\n",
    "        \"\"\":obj:`array` of shape = [n_classes]: The class label array.\"\"\"\n",
    "        if not self.__sklearn_is_fitted__():\n",
    "            raise LGBMNotFittedError('No classes found. Need to call fit beforehand.')\n",
    "        return self._classes  # type: ignore[return-value]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "class CustomLogger:\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger('lightgbm_custom')\n",
    "        self.logger.setLevel(logging.ERROR)\n",
    "\n",
    "    def info(self, message):\n",
    "        self.logger.info(message)\n",
    "\n",
    "    def warning(self, message):\n",
    "        # Suppress warnings by not doing anything\n",
    "        pass\n",
    "\n",
    "    def error(self, message):\n",
    "        self.logger.error(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.80519\n",
      "Test logloss 1.21619\n"
     ]
    }
   ],
   "source": [
    "lgb.register_logger(CustomLogger())\n",
    "model = CustomLGBMClassifier()\n",
    "params = {\n",
    " 'colsample_bytree': 0.7,\n",
    " 'learning_rate': 0.001,\n",
    " 'max_depth': 3,\n",
    " 'min_child_samples': 1,\n",
    " 'min_child_weight': 0.01,\n",
    " 'n_estimators': 150,\n",
    " 'num_leaves': 64,\n",
    "}\n",
    "model.set_params(**params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "print(f\"Test ROC AUC: {metrics.roc_auc_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Test logloss {metrics.log_loss(y_test, y_pred):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test ROC AUC: 0.97839\n",
    "Test logloss 0.00715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100],\n",
    "    'min_child_samples': [10, 20, 50],\n",
    "    'learning_rate': [0.001, 0.01, 0.05],\n",
    "    'obj_alpha': [0.01, 0.2, 0.5, 0.7],\n",
    "    'obj_gamma': [1, 2, 3]}\n",
    "]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = CustomLGBMClassifier()\n",
    "search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc')\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.001,\n",
       " 'max_depth': -1,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_leaves': 31,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0,\n",
       " 'verbosity': 10,\n",
       " 'obj_alpha': 1,\n",
       " 'obj_gamma': 0}"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from scipy import special\n",
    "\n",
    "class FocalLoss:\n",
    "\n",
    "    def __init__(self, gamma=0, alpha=None):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def at(self, y):\n",
    "        if self.alpha is None:\n",
    "            return np.ones_like(y)\n",
    "        return np.where(y, self.alpha, 1 - self.alpha)\n",
    "\n",
    "    def pt(self, y, p):\n",
    "        p = np.clip(p, 1e-15, 1 - 1e-15)\n",
    "        return np.where(y, p, 1 - p)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        at = self.at(y_true)\n",
    "        pt = self.pt(y_true, y_pred)\n",
    "        return -at * (1 - pt) ** self.gamma * np.log(pt)\n",
    "\n",
    "    def grad(self, y_true, y_pred):\n",
    "        y = 2 * y_true - 1  # {0, 1} -> {-1, 1}\n",
    "        at = self.at(y_true)\n",
    "        pt = self.pt(y_true, y_pred)\n",
    "        g = self.gamma\n",
    "        return at * y * (1 - pt) ** g * (g * pt * np.log(pt) + pt - 1)\n",
    "\n",
    "    def hess(self, y_true, y_pred):\n",
    "        y = 2 * y_true - 1  # {0, 1} -> {-1, 1}\n",
    "        at = self.at(y_true)\n",
    "        pt = self.pt(y_true, y_pred)\n",
    "        g = self.gamma\n",
    "\n",
    "        u = at * y * (1 - pt) ** g\n",
    "        du = -at * y * g * (1 - pt) ** (g - 1)\n",
    "        v = g * pt * np.log(pt) + pt - 1\n",
    "        dv = g * np.log(pt) + g + 1\n",
    "\n",
    "        return (du * v + u * dv) * y * (pt * (1 - pt))\n",
    "\n",
    "    def init_score(self, y_true):\n",
    "        res = optimize.minimize_scalar(\n",
    "            lambda p: self(y_true, p).sum(),\n",
    "            bounds=(0, 1),\n",
    "            method='bounded'\n",
    "        )\n",
    "        p = res.x\n",
    "        log_odds = np.log(p / (1 - p))\n",
    "        return log_odds\n",
    "\n",
    "    def lgb_obj(self, preds, train_data):\n",
    "        y = train_data.get_label()\n",
    "        p = special.expit(preds)\n",
    "        return self.grad(y, p), self.hess(y, p)\n",
    "\n",
    "    def lgb_eval(self, preds, train_data):\n",
    "        y = train_data.get_label()\n",
    "        p = special.expit(preds)\n",
    "        is_higher_better = False\n",
    "        return 'focal_loss', self(y, p).mean(), is_higher_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = FocalLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
